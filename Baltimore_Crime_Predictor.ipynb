{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "957d8680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"font-family:monospace;background:#e6fee6;color:black\"><pre>Packages already installed: ipython, joblib, pandas, requests, scikit-learn, tensorflow, tqdm</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family:monospace;background:lightyellow;color:black\"><pre>No new packages installed</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"font-family:monospace;background:#eee;color:black\"><pre>Done</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipydeps\n",
    "ipydeps.pip(['IPython',\n",
    "             'tensorflow',\n",
    "             'requests',\n",
    "             'tqdm',\n",
    "             'pandas',\n",
    "             'joblib',\n",
    "             'scikit-learn'],verbose=False)\n",
    "import IPython\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "# importing classes from other files that assist with the downloading and\n",
    "#  feature engineering of Baltimore's arcgis data\n",
    "from Baltimore_Data_Modules.BaltimoreDataExtraction import BmoreDataExtraction\n",
    "from Baltimore_Data_Modules.Bmore_FeatureEngineering import BmoreCrimeFeatureEngineering\n",
    "import Baltimore_Data_Modules.Model_Utils as Model_Utils\n",
    "\n",
    "def days_hours_minutes(td):\n",
    "    # function that is used for converting time into a readable format\n",
    "    return td.days, td.seconds//3600, (td.seconds//60)%60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34615cfc",
   "metadata": {},
   "source": [
    "# Initializing Baltimore Data Extraction class\n",
    "- The API link dictionary organizes each data set by type of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Baltimore_Data_Modules import BaltimoreDataExtraction\n",
    "\n",
    "Bmore_API_Crime_link_dict = {'FEAT_COLLECT':\n",
    "                             {#'911 Calls for Service 2022 Through Present':'https://services1.arcgis.com/UWYHeuuJISiGmgXx/ArcGIS/rest/services/911_CallsForService_PreviousYear_Present/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              #'BPD Arrests':'https://egis.baltimorecity.gov/egis/rest/services/GeoSpatialized_Tables/Arrest/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              #'Parking and Moving Citations':'https://services1.arcgis.com/UWYHeuuJISiGmgXx/arcgis/rest/services/Parking_and_Moving_Citations__view/FeatureServer/2/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              #'Gun Offenders Registry':'https://egis.baltimorecity.gov/egis/rest/services/GeoSpatialized_Tables/GunOffenders/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              'Part 1 Crime Data':'https://services1.arcgis.com/UWYHeuuJISiGmgXx/arcgis/rest/services/Part1_Crime_Beta/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson'},\n",
    "                             'CSA_DATA':\n",
    "                             {'Percent of Adult Population on Parole/Probation - Community Statistical Area':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Prbprl/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              'Property Crime Rate per 1,000 Residents - Community Statistical Area':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Prop/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              'Violent Crime Rate per 1,000 Residents - Community Statistical Area':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Viol/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              'Part 1 Crime Rate per 1,000 Residents - Community Statistical Area':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Crime/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              'Number of Gun-Related Homicides per 1,000 Residents - Community Statistical Area':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Gunhom/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              'Number of Arrests per 1,000 Residents - Community Statistical Area':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Arrests/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              'Domestic Violence Calls For Service per 1,000 Residents - Community Statistical Area':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Juvarr/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              'Juvenile Arrest Rate per 1,000 Juveniles - Community Statistical Area':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Juvarr/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              'Juvenile Arrest Rate for Violent Offenses per 1,000 Juveniles - Community Statistical Area':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Juvviol/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              'Juvenile Arrest Rate for Drug-Related Offenses per 1,000 Juveniles - Community Statistical Area':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Juvdrug/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                              'Number of Narcotics Calls for Service per 1,000 Residents - Community Statistical Area':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Narc/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson'},\n",
    "                             'CITY_DATA':\n",
    "                             {'Property Crime Rate per 1,000 Residents - City':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Prop/FeatureServer/1/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                             'Violent Crime Rate per 1,000 Residents - City':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Viol/FeatureServer/1/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                             'Part 1 Crime Rate per 1,000 Residents - City':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Crime/FeatureServer/1/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                             'Number of Gun-Related Homicides per 1,000 Residents - City':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Gunhom/FeatureServer/1/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                             'Number of Narcotics Calls for Service per 1,000 Residents - City':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Narc/FeatureServer/1/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                             'Number of Common Assault Calls for Service per 1,000 Residents - City':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Caslt/FeatureServer/1/query?outFields=*&where=1%3D1&f=geojson',\n",
    "                             'Number of Common Assault Calls for Service per 1,000 Residents - City':'https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/Caslt/FeatureServer/1/query?outFields=*&where=1%3D1&f=geojson'}\n",
    "                            }\n",
    "\n",
    "with open(\"Bmore_API_Crime_link.json\", \"w\") as outfile:\n",
    "    json.dump(Bmore_API_Crime_link_dict, outfile, indent=4)\n",
    "\n",
    "\n",
    "bde = BaltimoreDataExtraction.BmoreDataExtraction(Bmore_API_Crime_link_dict)\n",
    "bde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783e5fc7",
   "metadata": {},
   "source": [
    "# Downloading latest data set by type of data\n",
    "- next 3 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb180c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FEAT_COLLECT_Path_dict = bde.DownloadDataType(data_type_str='FEAT_COLLECT',includeAll=True)\n",
    "\n",
    "def Nested_featCol_Union(nestedPath_dict,chosenKey):\n",
    "    oneDataset_dict = nestedPath_dict[chosenKey]\n",
    "    oneDatasetDF_dict = bde.FeatureCollectionToDF(oneDataset_dict)\n",
    "    return {chosenKey:pd.concat(list(oneDatasetDF_dict.values()))}\n",
    "\n",
    "FEAT_COLLECT_DF_dict = Nested_featCol_Union(FEAT_COLLECT_Path_dict,'Part 1 Crime Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSA_DATA_Path_dict = bde.DownloadDataType('CSA_DATA')\n",
    "# CSA_DATA_DF_dict = bde.GeoDataToDF(CSA_DATA_Path_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf24f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CITY_DATA_Path_dict = bde.DownloadDataType('CITY_DATA')\n",
    "# CITY_DATA_DF_dict = bde.GeoDataToDF(CITY_DATA_Path_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657b2c5c",
   "metadata": {},
   "source": [
    "# Cleaning \"Part 1 Crime\" Data Specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9baef1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from Baltimore_Data_Modules import Bmore_FeatureEngineering\n",
    "\n",
    "crime_feat_dict = {'DROP':\n",
    "                        ['RowID',\n",
    "                         'Post',\n",
    "                         'Gender',\n",
    "                         'Age',\n",
    "                         'Race',\n",
    "                         'Ethnicity',\n",
    "                         'GeoLocation',\n",
    "                         'PremiseType',\n",
    "                         'Total_Incidents',\n",
    "                         'New_District'],\n",
    "                   'CATEGORICAL':\n",
    "                         ['CCNumber',\n",
    "                          'CrimeCode',\n",
    "                          'Description',\n",
    "                          'Inside_Outside',\n",
    "                          'Weapon',\n",
    "                          'Location',\n",
    "                          'Old_District',\n",
    "                          'Neighborhood'],\n",
    "                    'NUMERICAL':\n",
    "                         []}\n",
    "\n",
    "# instantiating feature engineering class\n",
    "bcfe = Bmore_FeatureEngineering.BmoreCrimeFeatureEngineering(geo_cols_li=['Latitude',\n",
    "                                                                          'Longitude'],\n",
    "                                                                          time_col_str='CrimeDateTime',\n",
    "                                                                          feat_col_dict=crime_feat_dict)\n",
    "# Initial Cleaning of Baltimore crime data\n",
    "Bmore_Crime_df = bcfe.CreateTimeIndexDF(FEAT_COLLECT_DF_dict['Part 1 Crime Data'])\n",
    "Bmore_Crime_df = bcfe.DropUnwantedFeatsDF(Bmore_Crime_df)\n",
    "Bmore_Crime_df = bcfe.GeoStatsDF(Bmore_Crime_df)\n",
    "# filtering to Datetimes that make sense\n",
    "Bmore_Crime_df = Bmore_Crime_df[Bmore_Crime_df.CrimeDateTime.astype(int) > 1000000000000] # 1600000000000\n",
    "Bmore_Crime_df.index = pd.DatetimeIndex(list(Bmore_Crime_df.index))\n",
    "print('Bmore Crime Shape:',Bmore_Crime_df.shape)\n",
    "\n",
    "# Extracting categorical and periodic features\n",
    "categorical_df = bcfe.CatFeatEncode(Bmore_Crime_df)\n",
    "periodicity_df = bcfe.PeriodicityEncode(Bmore_Crime_df)\n",
    "print('Categorical Feature Shape:',categorical_df.shape)\n",
    "print('periodicity Feature Shape:',periodicity_df.shape)\n",
    "\n",
    "# Merging features & scaling\n",
    "FINAL_X_df = pd.concat([categorical_df,periodicity_df],axis=1)\n",
    "print('Feature Shape (X):',FINAL_X_df.shape)\n",
    "# Separating Prediction targets\n",
    "FINAL_Y_df = Bmore_Crime_df[bcfe.geo_cols_].apply(pd.to_numeric)\n",
    "print('Target Shape (Y):',FINAL_Y_df.shape)\n",
    "\n",
    "# Combining everything together again\n",
    "FINAL_DF = pd.concat([FINAL_X_df,FINAL_Y_df],axis=1).sort_index()\n",
    "FINAL_DF = bcfe.DropZeroGeos(FINAL_DF)\n",
    "print('Final Shape Regular (X+Y):',FINAL_DF.shape)\n",
    "\n",
    "#resampling  for every hour\n",
    "RULE_str = '1H' # 1H for every hour and 1D for every day\n",
    "resampled_FINAL_DF = FINAL_DF.resample(rule=RULE_str).mean(numeric_only=True).interpolate(method='akima')\n",
    "resampled_FINAL_shape = resampled_FINAL_DF.shape\n",
    "print('Final Shape Resampled (X+Y):',resampled_FINAL_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b31a277",
   "metadata": {},
   "source": [
    "# Splitting Data Into Train, Validation, & Test Sets\n",
    "- Normalizing data based on features in training set. Using quantile transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c690aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def DataSplitter(df):\n",
    "    # Splitting training, validation, and test sets\n",
    "    column_indices_dict = {name: i for i, name in enumerate(df.columns)}\n",
    "    n = len(df)\n",
    "    TRAIN_DF = df[0:int(n*0.7)]\n",
    "    VAL_DF = df[int(n*0.7):int(n*0.9)]\n",
    "    TEST_DF = df[int(n*0.9):]\n",
    "    print('Train Shape:',TRAIN_DF.shape)\n",
    "    print('Train Datetime Range:',\n",
    "          str(TRAIN_DF.index.min())+' -> '+str(TRAIN_DF.index.max())+'\\n')\n",
    "    print('Validation Shape:',VAL_DF.shape)\n",
    "    print('Validation Datetime Range:',\n",
    "          str(VAL_DF.index.min())+' -> '+str(VAL_DF.index.max())+'\\n')\n",
    "    print('Test Shape:',TEST_DF.shape)\n",
    "    print('Test Datetime Range:',\n",
    "          str(TEST_DF.index.min())+' -> '+str(TEST_DF.index.max())+'\\n')\n",
    "    return {'TRAIN':TRAIN_DF,'VAL':VAL_DF,'TEST':TEST_DF}\n",
    "\n",
    "split_dict = DataSplitter(resampled_FINAL_DF)\n",
    "\n",
    "def NormalizeSplits(split_dict=split_dict):\n",
    "    # Normalizing data sets via L2\n",
    "    # Fitting to the training set\n",
    "    norm = QuantileTransformer().fit(split_dict['TRAIN'])\n",
    "    # Transforming all the split sets\n",
    "    scaled_TRAIN_DF = pd.DataFrame(norm.transform(split_dict['TRAIN']),\n",
    "                                   columns=norm.get_feature_names_out(),\n",
    "                                   index=split_dict['TRAIN'].index)\n",
    "    scaled_VAL_DF = pd.DataFrame(norm.transform(split_dict['VAL']),\n",
    "                                   columns=norm.get_feature_names_out(),\n",
    "                                   index=split_dict['VAL'].index)\n",
    "    scaled_TEST_DF = pd.DataFrame(norm.transform(split_dict['TEST']),\n",
    "                                    columns=norm.get_feature_names_out(),\n",
    "                                    index=split_dict['TEST'].index)\n",
    "    return norm, {'TRAIN':scaled_TRAIN_DF,'VAL':scaled_VAL_DF,'TEST':scaled_TEST_DF}\n",
    "\n",
    "norm, scaled_split_dict = NormalizeSplits(split_dict)\n",
    "\n",
    "# Creating violin plot to show data features\n",
    "voilin_df = scaled_split_dict['TRAIN'].melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=voilin_df)\n",
    "_ = ax.set_xticklabels(list(scaled_split_dict['TRAIN'].columns), rotation=90)\n",
    "plt.title('Training Data Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ebdf2",
   "metadata": {},
   "source": [
    "# Data Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bddb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Baltimore_Data_Modules import Model_Utils\n",
    "\n",
    "## Creating a multistep output to predict more than one window at a time\n",
    "\n",
    "# OUT_STEPS = 7*2 # Each time step is 1 day. 7 days in a week\n",
    "# INPUT_STEPS = 30*2 # Each time step is 1 day. About 30 days in a month\n",
    "OUT_STEPS = 168*2 # Each time step is 1 hour. 168 hours in a week\n",
    "INPUT_STEPS = 730*2 # Each time step is 1 hour. 730 hours in a month\n",
    "num_features = resampled_FINAL_shape[1]\n",
    "\n",
    "wg = Model_Utils.WindowGenerator(input_width=INPUT_STEPS,\n",
    "                                 label_width=OUT_STEPS,\n",
    "                                 label_columns=None, # Originally just latitude\n",
    "                                 shift=OUT_STEPS,\n",
    "                                 split_dict=scaled_split_dict)\n",
    "wg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80616c1f",
   "metadata": {},
   "source": [
    "# Training LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60678af",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 20\n",
    "multi_val_performance = {}\n",
    "multi_performance = {}\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "    # Created using M1/M2 Mac hence the use of \"tf.keras.optimizers.legacy.Adam\" instead of \"tf.keras.optimizers.Adam\"\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(), \n",
    "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "    return history\n",
    "\n",
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units].\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    # Shape => [batch, out_steps*features].\n",
    "    tf.keras.layers.Dense(OUT_STEPS*num_features,\n",
    "                          kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features].\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, num_features])\n",
    "])\n",
    "train_start = datetime.now()\n",
    "history = compile_and_fit(multi_lstm_model, wg)\n",
    "IPython.display.clear_output()\n",
    "train_finish = datetime.now() - train_start\n",
    "print('Total Training Time {d}:{h}:{m}'.format(d=days_hours_minutes(train_finish)[0],\n",
    "                                               h=days_hours_minutes(train_finish)[1],\n",
    "                                               m=days_hours_minutes(train_finish)[2]))\n",
    "\n",
    "multi_val_performance['LSTM'] = multi_lstm_model.evaluate(wg.val)\n",
    "multi_performance['LSTM'] = multi_lstm_model.evaluate(wg.test, verbose=0)\n",
    "multi_lstm_model.save(os.getcwd() + '/Bmore_Crime_Predict_Model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0948ef",
   "metadata": {},
   "source": [
    "# Plotting Fit Examples From Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1246f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wg.plot(multi_lstm_model,plot_col=bcfe.geo_cols_[0])\n",
    "wg.plot(multi_lstm_model,plot_col=bcfe.geo_cols_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9114ee4a",
   "metadata": {},
   "source": [
    "# LSTM Inference On Latest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748915af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Displaying metadata about model \n",
    "print('Input Shape:',multi_lstm_model.input_shape)\n",
    "print('Output Shape:',multi_lstm_model.output_shape)\n",
    "display(multi_lstm_model.summary())\n",
    "\n",
    "## Getting the latest crime data and preparing for inference\n",
    "deploy_df = wg.test_df.tail(INPUT_STEPS)\n",
    "deploy_shape_tu = deploy_df.shape\n",
    "deploy_ar = np.reshape(deploy_df.values,newshape=(1,deploy_shape_tu[0],deploy_shape_tu[1]))\n",
    "\n",
    "## Obtaining forecasted datetime range\n",
    "LATEST_DATETIME = deploy_df.tail(1).index[0]\n",
    "FORECAST_DATE_RANGE = pd.date_range(start=LATEST_DATETIME,\n",
    "                                    freq='1H',\n",
    "                                    periods=OUT_STEPS+1)[1:]\n",
    "\n",
    "## Generating inference and scaling back to original data\n",
    "forecast_ar = multi_lstm_model.predict(deploy_ar)\n",
    "forecast_df = pd.DataFrame(norm.inverse_transform(forecast_ar[0]),\n",
    "                           columns=wg.column_indices,\n",
    "                           index=FORECAST_DATE_RANGE)\n",
    "geo_forecast_df = forecast_df[bcfe.geo_cols_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de47ca0",
   "metadata": {},
   "source": [
    "# Visualizing Predicted Crime Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e975b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "geo_forecast_li = geo_forecast_df.values.tolist()\n",
    "\n",
    "map_folium = folium.Map(location=[39.299236, -76.609383],\n",
    "                  tiles=\"OpenStreetMap\",\n",
    "                  zoom_start=10)\n",
    "\n",
    "for coord_index in range(len(geo_forecast_df)):\n",
    "    pred_datetime_str = str(geo_forecast_df.iloc[coord_index].name)\n",
    "    coordinates_li = geo_forecast_li[coord_index]\n",
    "    map_folium.add_child(folium.Marker(location=coordinates_li,\n",
    "                         popup='Prediction Datetime:<br>'\n",
    "                         +pred_datetime_str))\n",
    "map_folium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd926c",
   "metadata": {},
   "source": [
    "# Calculating different forms of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926961f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_sigma_se = FINAL_DF.describe().loc['std']\n",
    "lat_error = geo_sigma_se[bcfe.geo_cols_[0]]\n",
    "lon_error = geo_sigma_se[bcfe.geo_cols_[1]]\n",
    "train_error = multi_val_performance['LSTM'][1]\n",
    "test_error = multi_performance['LSTM'][1]\n",
    "\n",
    "geo_uncertainty = math.sqrt((lat_error**2)+(lon_error**2))\n",
    "model_error = math.sqrt((train_error**2)+(test_error**2))\n",
    "print('Geo Uncertainty:',geo_uncertainty)\n",
    "print('Model Error:',model_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bb4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da1699c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
